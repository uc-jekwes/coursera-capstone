{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# **The Battle of the Neighborhoods - Week 2**\n\nPart 2 Web scrapping of Neigborhood, Zip Codes and Covid 19 information\n\n**A : NEIGBORHOOD AND ZIP CODES DATA**\n\nWeb scrapping of Population data from Health New York - https://www.health.ny.gov/statistics/cancer/registry/appendix/neighborhoods.htm\n\nDownload all the dependencies that is needed."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!pip install beautifulsoup4\n!pip install lxml\nimport requests # library to handle requests\nimport pandas as pd # library for data analsysis\nimport numpy as np # library to handle data in a vectorized manner\nimport random # library for random number generation\n\n#!conda install -c conda-forge geopy --yes \nfrom geopy.geocoders import Nominatim # module to convert an address into latitude and longitude values\n\n# libraries for displaying images\nfrom IPython.display import Image \nfrom IPython.core.display import HTML \n\n\nfrom IPython.display import display_html\nimport pandas as pd\nimport numpy as np\n    \n# tranforming json file into a pandas dataframe library\nfrom pandas.io.json import json_normalize\n\n!conda install -c conda-forge folium=0.5.0 --yes\nimport folium # plotting library\nfrom bs4 import BeautifulSoup\nfrom sklearn.cluster import KMeans\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\nprint('Folium installed')\nprint('Libraries imported.')",
            "execution_count": null,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Requirement already satisfied: beautifulsoup4 in /opt/conda/envs/Python36/lib/python3.6/site-packages (4.7.1)\nRequirement already satisfied: soupsieve>=1.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from beautifulsoup4) (1.7.1)\nRequirement already satisfied: lxml in /opt/conda/envs/Python36/lib/python3.6/site-packages (4.3.1)\nSolving environment: | ",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "**Web scrapping of Population data from wikipedia page using BeautifulSoup.**\n\nBeautiful Soup is a Python package for parsing HTML and XML documents (including having malformed markup, i.e. non-closed tags, so named after tag soup). It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "source = requests.get('https://www.health.ny.gov/statistics/cancer/registry/appendix/neighborhoods.htm').text\nsoup=BeautifulSoup(source,'html')\nprint(soup.title)\nfrom IPython.display import display_html\ntab = str(soup.table)\ndisplay_html(tab,raw=True)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "dfs = pd.read_html(tab)\ndf=dfs[0]\ndf.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!wget -q -O 'newyork_data.json' https://ibm.box.com/shared/static/fbpwbovar7lf8p5sgddm06cgipa2rxpe.json\nprint('Data downloaded!')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "with open('newyork_data.json') as json_data:\n    newyork_data = json.load(json_data)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "neighborhoods_data = newyork_data['features']\nneighborhoods_data[0]",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "**Tranform the data into a pandas dataframe**\n\nThe next task is essentially transforming this data of nested Python dictionaries into a pandas dataframe. Start by creating an empty dataframe."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# define the dataframe columns\ncolumn_names = ['Borough', 'Neighborhood', 'Latitude', 'Longitude'] \n\n# instantiate the dataframe\nneighborhoods = pd.DataFrame(columns=column_names)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Then loop through the data and fill the dataframe one row at a time"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "for data in neighborhoods_data:\n    borough = neighborhood_name = data['properties']['borough'] \n    neighborhood_name = data['properties']['name']\n        \n    neighborhood_latlon = data['geometry']['coordinates']\n    neighborhood_lat = neighborhood_latlon[1]\n    neighborhood_lon = neighborhood_latlon[0]\n    \n    neighborhoods = neighborhoods.append({'Borough': borough,\n                                          'Neighborhood': neighborhood_name,\n                                          'Latitude': neighborhood_lat,\n                                          'Longitude': neighborhood_lon}, ignore_index=True)\n\nneighborhoods.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df2=pd.merge(df,neighborhoods,on= 'Neighborhood')\ndf2.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "source = requests.get('https://github.com/nychealth/coronavirus-data/blob/master/boro.csv').text\nsoup=BeautifulSoup(source,'lxml')\nprint(soup.title)\nfrom IPython.display import display_html\ntab = str(soup.table)\ndisplay_html(tab,raw=True)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df4 = pd.read_html(tab)\ndf=df4[0]\ndf.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df3=pd.merge(df,neighborhoods,left_on='BOROUGH_GROUP', right_on='Borough')\ndf3.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df4=df3.dropna(axis='columns')\ndf4.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df5=df4.drop(columns='BOROUGH_GROUP')\ndf5.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "CLIENT_ID = '402RXOBDXFHKXVGEZSM3USD4FD2YLOZMCHF4JLLUN1KI5G5D' # your Foursquare ID\nCLIENT_SECRET = 'YH2BIDZCC21G0Y1YGATQGY553RJOEKZQM5R1DS544YWCD5FZ' # your Foursquare Secret\nVERSION = '20200401'",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "map_newyork = folium.Map(location=[40.7308619,-73.9871558],zoom_start=10)\n\nfor lat,lng,borough,neighbourhood in zip(df5['Latitude'],df5['Longitude'],df5['Borough'],df5['COVID_CASE_COUNT']):\n    label = '{}, {}'.format(neighbourhood, borough)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n    [lat,lng],\n    radius=5,\n    popup=label,\n    color='blue',\n    fill=True,\n    fill_color='#3186cc',\n    fill_opacity=0.7,\n    parse_html=False).add_to(map_newyork)\nmap_newyork",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### **Using Histogram to show the distribution**"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df6=df.drop(columns='COVID_CASE_RATE')\ndf6.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "df7=df6.dropna(axis='columns')\ndf7.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df7.plot(kind='hist', figsize=(10, 6))\n\nplt.title('Histogram of Immigration from Denmark, Norway, and Sweden from 1980 - 2013')\nplt.ylabel('COVID_CASE_COUNT')\nplt.xlabel('BOROUGH_GROUP')\n\nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "plt.figure(figsize=(15,10))\ndf7.sort_values(by=\"points\",ascending=False)[\"points\"].plot.bar()\nplt.xticks(rotation=50)\nplt.xlabel(\"BOROUGH_GROUP\")\nplt.ylabel(\"COVID_CASE_COUNT\")\nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# install wordcloud\n!conda install -c conda-forge wordcloud==1.4.1 --yes\n\n# import package and its set of stopwords\nfrom wordcloud import WordCloud, STOPWORDS\n\nprint ('Wordcloud is installed and imported!')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# download file and save as alice_novel.txt\n!wget --quiet https://github.com/nychealth/coronavirus-data/blob/master/boro.csv\n\n# open the file and read it into a variable alice_novel\nBoro = open('boro.csv', 'r').read()\n    \nprint ('File downloaded and saved!')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "stopwords = set(STOPWORDS)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# instantiate a word cloud object\nboro_wc = WordCloud(\n    background_color='white',\n    max_words=2000,\n    stopwords=stopwords\n)\n\n# generate the word cloud\nboro_wc.generate(Boro)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# display the word cloud\nplt.imshow(boro_wc, interpolation='bilinear')\nplt.axis('off')\n\nfig = plt.figure()\nfig.set_figwidth(30)\nfig.set_figheight(45)\n\nplt.show()",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}